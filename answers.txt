# Fill in your name, student ID, and email address in this file.
# If you are working in a team, fill out the information for both team 
# members.

# SUBMIT THE LAB ONLY ONCE (from only one partner). This file will be
# automatically parsed in order to give both team members credit for the
# lab.

# You need to fill in the EXERCISE sections describing your solutions
# for Tasks 1, 2, and 3, as well as write the corresponding code.
# If you did one or more extra credit problems, indicate which one in the
# appropriate section below (remove the # sign first). If you have any other
# information you'd like us to know, please add it at the end of the file.

# Partner 1
Name: Daniel Yao
Student ID: 004-182-464
Email: Daniel988@ucla.edu

# Partner 2 (if you're working in a team)
Name: Setiawan Makmur
Student ID: 704-209-040
Email: setiawan987@hotmail.com

# EXERCISE 1: What method you used to make your peer download and upload
#    files in parallel?  (~1-3 sentences)
To make our p2p client download and upload in parallel we used fork()
to queue up multiple download/upload requests. Then inside the child processes
we would run the necessary codes needed to download/upload files from/to peers,
such as task_download() and task_upload().

# EXERCISE 2A: What conditions did you find and fix that would have
#    triggered a buffer overrun bug?  (~1-3 sentences each)
Basically, whenever we use strcpy, to cpy the filenames for downloading/uploading.
We changed strcpy() to the safer strncpy(), and used strnlen() to get the filename
in the cases of downloading request, compared it to FILENAMESIZ, and also appending
a nullbyte at either the filename length's or at index FILENAMESIZ if the length is longer.
This insures that we won't get buffer overflows when writing to the filename buffer.

# EXERCISE 2B: What other robustness problems did you fix?  (~1-3 sentences
#    each)
We added preventions for DDOS/infinite forking, infinite sized files protections,
and protections against trying to request files from us that's not within the immediate directory.

DDOS occurs when a peer repeatedly asks us to upload, and since we fork each time,
it can crash our system. To prevent this, we created a limit to the maximum number
of concurrent running upload processes of 8. Whenever we fork, we would increment
this counter by 1, and we don't fork unless the counter is less than 8. When it is
less than 5, we will wait until 1 upload process finishes before forking another.

To prevent infinite sized files when we download, we added a hard limit of 1MB
for any file we download. The file size limit should actually be kept by the tracker,
but for this lab the tracker doesn't keep track of the size of files, so we're using 
a hard limit of 1MB. Once we've written more than this amount to disk, we will quit the
downloading process and attempt to delete the downloaded file. We chose 1MB since the 
cat images are only 40KB large, so 1MB is plenty large.

To limit where peers can download files from us, we implemented a check to look for any
'/' characters, which are not allowed as file names in Linux. We also checked if the first
character is a nullbyte, which indicates an empty file name, which may cause errors. In both
case, once dectected, we goto exit and remove the upload task.

# EXERCISE 3: Describe the attacks you implemented for "evil mode".  Why
#    are they attacks?  (~3-10 sentences each)
The first attack is a buffer overflow attack aimed toward a peer when we request a download
from them. What we do is, when we use the oosp2p_writef() to connect to the peer, instead of
asking for the proper file name stored in t->filename, we ask for some random name of 5000 bytes
long. If the peer does not properly check for our request, they will attempt to copy 5000 bytes
to their buffers and thus overflowing their buffers. We also added an line that if uncommented
would try to download "./answers.txt" from the peer's computer

The second attack we created is to upload an infinite amount of bytes to the downloader,
potentially flooding their diskspace and corrupting other data. The way we do this is whenever
we upload, we would always move the file pointer back to the beginning upon reaching the
end of whatever file we're trying to upload. Doing this cases upload to never finish. If the downloader
does not have protection that limits the amount of data that can be downloaded then this attack
can be dangerous to the downloader by filling up their hard drive


# Extra credit problems
#Extra credit problem: none

# Add any other information you'd like us to know below this line.
We're also doing the design problem for this lab. And it was very hard to test our code for
this lab because the trackers were not working.